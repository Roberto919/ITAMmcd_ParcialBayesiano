---
title: "Examen parcial - Primavera 2021"
author: Alfredo Garbuno Iñigo
output: html_document
---

**Entrega:** 

Enviar por correo electrónico una carpeta comprimida
(`equipo-xx.zip`) que incluya datos y codigo de solución a mas tardar el 23 de
Marzo antes de las 11:59pm (medianoche). El asunto deberá ser `[MB - 2021]
Parcial Equipo XX`, donde  reemplazarás `XX` con el codigo de tu equipo. No se
aceptarán entregas extemporáneas. Será mejor entregar un examen resuelto
parcialmente, que no entregar nada.

**Instrucciones:**
  
* Tus respuestas deben ser claras y debes explicar los resultados, incluye
también tus procedimientos/código de manera ordenada, y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas,
...).

* Las sesiones de dudas del Miércoles 17 de Marzo será completamente para
responder dudas del examen. Adicionalmente, en las sesiones del Martes 16 y
Jueves 18 se reservará una media hora para dudas (dependerá de la agenda cuál
será el momento más oportuno para abrir el espacio).

* No pueden compartir soluciones entre diferentes equipos.

* Al entregar este examen afirmas que el trabajo se realizó sólo con tu
compañeros de equipo. El material que utilizaste para apoyarte consistió de las
notas en clase (pdfs en Canvas), el codigo fuente de las notas en el repositorio
de Github.

* Al entregar estás dando tu consentimiento para que bajo sospecha y suficiente
evidencia de copia se anule tu evaluación.

**Ponderación:**

El examen está compuesto por tres apartados cuyo peso son los siguientes: 
1. Datos !Kung San (60%)
2. Datos Vinos     (25%)
3. Datos Nettle    (15%)


```{r setup, include=FALSE}
install.packages("tidybayes")
install.packages("ggpubr")
library(modelr)
library(tidybayes)
library(tidymodels)
library(tidyverse)
library(cmdstanr) #ajusta modelos bayesianos con stan
library(rstanarm) #ajusta modelos bayesianos con stan
library(bayesplot)
library(loo) #criterios de información
library(patchwork) #mejora visualización
library(scales)
library(ggplot2) #genera gráficos
library(ggpubr)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE, 
                      fig.align = 'center', fig.width = 5, fig.height=3, cache = TRUE)
comma <- function(x) format(x, digits = 2, big.mark = ",")
theme_set(theme_linedraw())
```

## Datos: !Kung San.

Los datos que tenemos en `Howell.csv` son datos parciales del censo para el
área de Dobe, en particular para la población de los [!Kung
San.](https://es.wikipedia.org/wiki/!Kung) Éstos fueron recopilados a partir de
entrevistas realizadas por Nancy Howell a finales de la década de 1960.

a ) Los pesos presentados a continuación se registraron en el censo !Kung, pero no
se registraron las alturas para estas personas. Proporciona predicciones para
las alturas e intervalos del 89% para cada uno de estos individuos basados en un
modelo de regresión lineal.

```{r}
pesos<-tibble(peso = c(46.95, 43.72, 64.78, 32.59, 54.63))
pesos
```


Dado que queremos generar predicciones para las alturas y sólo tenemos los pesos, decidimos utilizar un modelo de regresión lineal bajo un enfoque bayesiano utilizando como variable predictora el peso.

```{r}
datos1<-read_delim("howell.csv", delim = ";" ) #Cargamos los datos
```

Para lo cual, primero haremos un análisis exploratorio a los datos parciales del censo para conocer más al respecto.

```{r}
howell<-datos1 #hacemos una copia de los datos originales
head(howell) #imprimimos las primeras observaciones
```

```{r}
dim(howell)
```

```{r}
howell$genero<-factor(howell$genero) #Convertimos la variable a factor
summary(howell) #generamos resumen de las estadísticas
```

Primero identificamos que nuestro conjunto de datos contiene únicamente 544 observaciones y 4 columnas. Donde la variable a predecir (altura) se encuentra en centímetros, el peso en kg, la edad en años y el género es un indicador de sexo masculino cuando toma el valor de 1.

Después vemos que la muestra contiene a personas de 0 a 88 años de edad con pesos que van de los 4 kilos a los 63. Sin embargo, llama nuestra atención que aunque la mediana de altura está alrededor de 1.5 metros, la mediana de la edad corresponde a una persona adulta con 27 años de edad y 40 kg de peso. Para definir la distribución previa de los parámetros, decidimos que no tenemos suficiente conocimiento previo para poder proponerla con un suficiente conocimiento del problema.  Debido a ello, utilizamos el default de la distribución que proporciona stan_glm (una distribución poco informativa) para no sesgar nuestro modelo, asumieendo distribuciones previas normales para los coeficientes.

```{r}
SEED <- 2021 #proponemos una semilla para reproducibilidad
set.seed(SEED)
fit_1a <- stan_glm(altura ~ peso, data = howell, seed=SEED, refresh = 0) #generamos el modelo lineal bayesiano
print(fit_1a) #imprimimos el objeto con el modelo
```

Lo anterior nos dice que la predicción es precisa hasta más / menos 9.4 unidades que en este caso son centímetros.

```{r}
prior_summary(fit_1a) #imprimimos el resumen con las priors de default que usa stan_glm para nuestros datos
```

Como comentamos, la distribución previa que utilizamos es la de default la cual parte de nuestra muestra de 544 observaciones. Esto es, para el intercepto utiliza la altura media de nuestros datos con una desviación estándar de 2.5 para el intercepto y el peso.

```{r}
summary(fit_1a) #mostramos el resumen del modelo
```


Ahora utilizaremos la función posterior_predict() para calcular las predicciones de altura con base en los pesos de los 5 individuos bajo nuestro modelo de regresión ya que considera la incertidumbre asociada a los coeficientes del modelo y al error observacional (epsilon) incorporando sigma o el error aditivo.

```{r}
post_predict_1a<-as_tibble(posterior_predict(fit_1a, newdata=pesos,seed=SEED)) %>%  #genera predicciones de las 5 nuevas observaciones incorporando toda la incentidumbre asociada a los coeficientes y el error observacional
  #cada fila es una simulación bajo una muestra distinta
  mutate(sample_id = 1:4000) %>% #creamos ID para cada muestra
  pivot_longer(cols = 1:5) %>% #genera columna con predicciones por cada muestra
  mutate(name = fct_inorder(name)) %>% #ordenamos
  group_by(name) %>% #name es la predicción de cada individuo (1-5)
  summarise(altura_prom=mean(value), #calculamos la media de las predicciones
            altura_mediana=median(value), #calculamos la mediana de las predicciones
            altura_lim_inf=quantile(value,.055), #intervalos del 89% de probabilidad
            altura_lim_sup=quantile(value,.945))

post_predict_1a<-post_predict_1a %>% #agregamos los pesos observados de los individuos a las predicciones de la altura
  mutate(pesos)

post_predict_1a %>% mutate_if(is.numeric, ~round(., 1)) #mostramos los resultados redondeando a 1 cifra
```

```{r}
#Graficamos las predicciones de la posterior del modelo para la altura (media y bandas del 89%) incorporando los datos observados
g_1a<-post_predict_1a %>% #usamos las predicciones que obtuvimos con la función posterior_predict()
  ggplot(aes(peso,altura_prom)) + #graficamos peso vs altura_prom
  geom_ribbon(aes(ymin=altura_lim_inf,ymax=altura_lim_sup),fill = "grey70",alpha=.3) + #bandas de predicción
  geom_line(color="red") + #media de predicciones
  geom_jitter(data=howell %>% filter(peso>32), #agregamos los datos de la muestra filtrándolas con peso mayor a 32 
              aes(peso,altura),
              height = 0, width = 0.01, colour="darkblue") +
  labs(title = "Predicciones del modelo lineal altura ~ peso I=89%") + 
  labs(y = "altura")
g_1a
```

b) Ajusta un modelo lineal para personas menores de 18 años de edad utilizando
como predictores la `edad` y el `peso`. Interpreta los coeficientes que resultan
del modelo. Si consideras necesario centra los valores de las variables
predictoras.

Primero filtramos la muestra con las personas menores a 18 años

```{r}
menores.edad<-datos1 %>% filter(edad < 18) #copiamos la muestra filtrando por los individuos con edades menores a 18 años
menores.edad$genero<-factor(menores.edad$genero) #convertimos la variable a factor
summary(menores.edad) #generamos resumen de las estadísticas
```

Calculamos un resumen con estadísticas de dispersión, en este caso la mediana de la edad es de sólo 7 años y la muestra se reduce a 192 observaciones: 92 varones y 100 mujeres. La altura promedio de los datos ahora es de sólo 108 centímetros o 1.08 metros.

Posteriormente, centramos las variables alrededor de su media para poder dar una interpretación más sencilla al modelo lineal para predecir la altura:

```{r}
peso.centrado<-as.data.frame(scale(menores.edad$peso,scale=FALSE)) #centramos peso alrededor de su media
colnames(peso.centrado)<-c("peso.centrado") #lo nombramos peso.centrado
edad.centrada<-as.data.frame(scale(menores.edad$edad,scale=FALSE)) #centramos edad alrededor de su media
colnames(edad.centrada)<-c("edad.centrada") #lo nombramos peso.centrado
menores.edad<-cbind(menores.edad,peso.centrado,edad.centrada) #integramos las variables en menores.edad
head(menores.edad) #imprimimos las primeras observaciones
```

Y generamos el modelo con ambos predictores centrados:

```{r}
fit_1b <- stan_glm(altura ~ peso.centrado + edad.centrada, data = menores.edad, seed=SEED, refresh = 0) #generamos el modelo lineal bayesiano
print(fit_1b) #imprimimos el objeto con el modelo
```

Obtenemos un resumen del modelo:

```{r}
summary(fit_1b) #generamos resumen de las estadísticas
```

De los resultados anteriores, vemos que el intercepto representa la altura promedio de los menores de 18 años para una persona con un peso y edad alrededor del promedio la cual corresponde a 108 cm o 1.08 metros como vimos al inicio. Por otro lado, el peso y edad centrada tienen un coeficiente positivo en el modelo, lo cual indica para ambos predictores un incremento sobre el valor promedio centrado del peso y la edad contribuyen a un aumento sobre la predicción de la altura. En el caso del peso.centrado, por cada incremento de una unidad, predicción de la altura aumenta 1.4 cm la altura mientras que en la edad centrada por cada incremento de una unidad, la predicción de altura sube 2.3cm adicionales.

c) Para el modelo resultante, haz gráficos que muestren la relación de la
variable objetivo con los predictores. De igual forma, incorpora en la
visualización la respuesta del modelo lineal junto con intervalos de predicción
al 89\% y 97\%, de tal forma que incorpores la incertidumbre que se ha
cuantificado en tu gráfico.

```{r}
#Gráfico Dispersión altura vs predictor 1: peso.centrado
g_1c_altura_peso.centrado<-menores.edad %>% 
  ggplot(aes(x=peso.centrado,y=altura)) +
  geom_point()+
  geom_smooth(method = "lm")+
  labs(title = "Altura vs predictor 1")

#Gráfico Dispersión altura vs predictor 2: edad.centrada
g_1c_altura_edad.centrada<-menores.edad %>%
  ggplot(aes(x=edad.centrada,y=altura)) +
  geom_point()+
  geom_smooth(method = "lm")+
  labs(title = "Altura vs predictor 2")

#Gráfico altura vs predictor 1: peso.centrado
g_1c_altura_pred_peso<-ggplot(data = menores.edad, aes(x = peso.centrado, y = altura))  + 
    geom_abline(data = as_tibble(fit_1b) %>% sample_frac(.2), 
                aes(slope = peso.centrado, intercept = `(Intercept)`), 
                color = 'grey', alpha = .4) + 
    geom_abline(slope = coef(fit_1b)[2], intercept = coef(fit_1b)[1], color = 'salmon') + 
    geom_point()+
  labs(title = "Altura vs respuesta 1")

#Gráfico altura vs predictor 2: edad.centrada
g_1c_altura_pred_edad<-ggplot(data = menores.edad, aes(x = edad.centrada, y = altura))  + 
    geom_abline(data = as_tibble(fit_1b) %>% sample_frac(.2), 
                aes(slope = edad.centrada, intercept = `(Intercept)`), 
                color = 'grey', alpha = .4) + 
    geom_abline(slope = coef(fit_1b)[1], intercept = coef(fit_1b)[2], color = 'salmon') + 
    geom_point()+
  labs(title = "Altura vs respuesta 2")

g_1c_altura_peso.centrado+g_1c_altura_pred_peso+g_1c_altura_edad.centrada+g_1c_altura_pred_edad
```
Se aprecia una relación cercana a la lineal con ambos predictores.

d) Supongamos que tenemos una amiga que es experta en
[alometría](https://es.wikipedia.org/wiki/Alometr%C3%ADa) y les menciona que el
peso es suficiente, pero que se debería de incorporar en términos de una escala
logarítmica. Ajusta el modelo con todos las observaciones y compara con el
modelo del inciso a) y un modelo adicional que sólo incorpora el `peso`. ¿Cuál
parece tener mejor capacidad predictiva?

Primero creamos la variable log.peso donde calculamos el logaritmo natural aplicado al peso sobre todas las observaciones de nuestra muestra.

```{r}
howell<-howell %>% 
  mutate(log.peso = log(peso)) #creamos la variable log.peso aplicando el logaritmo natural al peso

head(howell) #imprimimos las primeras observaciones
```
Luego ajustamos el modelo:

```{r}
fit_1d_v1 <- stan_glm(altura ~ log.peso, data = howell, seed=SEED, refresh = 0) #generamos el modelo lineal bayesiano
summary(fit_1d_v1) #mostramos el resumen del modelo
```

Después de calcular este modelo, observamos que el coeficiente del intercepto es negativo. Por ello, se decidió crear una nueva variable log.peso.centrado centrando log.peso alrededor de su media para generar una interpretación del modelo.

```{r}
howell<-howell %>%
  mutate(log.peso.centrado = log.peso-mean(log.peso)) #creamos la variable log.peso.centrado centrando por la media

head(howell) #imprimimos las primeras observaciones
```

Y volvemos a ajustar un modelo:

```{r}
fit_1d <- stan_glm(altura ~ log.peso.centrado, data = howell, seed=SEED, refresh = 0) #generamos el modelo lineal bayesiano
summary(fit_1d) #mostramos el resumen del modelo
```

Ya que el signo del coeficiente es positivo, nos quedaremos con esta versión para compararla con el del inciso a). Es decir, utilizamos los criterios de información de los modelos para medir la capacidad predictiva del modelo del inciso a) y d) por medio de la devianza y log-densidad haciendo uso de validación cruzada con los métodos de waic y loo.

Primero calculamos la devianza de ambos modelos con waic:

```{r}
waic_1a<-waic(fit_1a) #calcula: elpd_waic que corresponde a la log-densidad; p_waic: el número efectivo de parámetros; waic: la devianza del modelo así como suss errores estándar variando sobre todas las observaciones
waic_1d<-waic(fit_1d) #calcula: elpd_waic que corresponde a la log-densidad; p_waic: el número efectivo de parámetros; waic: la devianza del modelo así como suss errores estándar variando sobre todas las observaciones

comparativo_waic_1d<-cbind(waic_1a,waic_1d) #combina resultados para comparar
comparativo_waic_1d
```

Y los resultados arrojan que el modelo es el d) que incorpora el peso en escala logarítmica como predictor tiene un mejor desempeño ya que es el de menor devianza 3,330 en contraste con el del inciso a) 3,982.

Luego generamos un comparativo en términos de la log-densidad predictiva con el método loo_compare().

```{r}
comparativo_diff_waic_1d<-loo_compare(waic_1a,waic_1d) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_waic_1d #imprime comparativo
```

Estos resultados también identifican al modelo del inciso d como el mejor pues tiene una mayor log-densidad predictiva. Además se aprecia una diferencia relativamente grande en la log-densidad predictiva y el error estándar del modelo d) con respecto al del inciso a).

Por último comparamos los modelos con validación cruzada mediante la función loo():

```{r}
loo_1a<-loo(fit_1a) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1a #imprime resultados 
```

```{r}
loo_1d<-loo(fit_1d) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1d #imprime resultados 
```
En ambos casos, el diagnóstico que loo arroja es que ambos modelos son buenos y además notamos que las estadísticas coinciden con las obtenidas con el método waic. Por lo que la conclusión no cambia, el mejor modelo también se determina que el modelo del inciso d) es el mejor bajo esta comparación.

```{r}
comparativo_diff_loo_1d<-loo_compare(loo_1a,loo_1d) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_loo_1d #imprime comparativo
```

e) ¿Cómo interpretas los coeficientes del mejor modelo del inciso `d`?

Como ya mencionamos, el mejor modelo para la predicción de la variable altura fue el d: altura ~ log.peso.centrado, donde utilizamos la variable log(peso) que fue centrada alrededor de su media. Primero mostramos los coeficientes de este modelo:

```{r}
print(fit_1d) #imprimimos el objeto con el modelo
```

De lo anterior se interpreta al intercepto de 138.3 como la estimación para la altura promedio en centímetros de un individuo promedio con un log.peso.centrado promedio (log-kg). El valor del coeficiente $\beta_1$ para la variable log.peso.centrado de 47.1 significa que un incremento de una unidad en la variable log.peso.centrado aumenta 47.1 cm la predicción sobre la altura del individuo.

f) Ahora estudiaremos el efecto de la distribución previa. Para esto
consideraremos. La variable de `edad` centrada y probaremos distintos polinomios
como predictores. Consideraremos potencias desde 0 hasta términos de grado 6.
Ajusta esta colección de posibles modelos. 

Primero calculamos la variable edad.centrada centrando la variable edad alrededor de su media:

```{r}
howell.centrado<-datos1 %>% 
  mutate(edad.centrada = edad-mean(edad)) #creamos la variable edad.centrada centrando la variable edad por su media
howell.centrado$genero<-factor(howell$genero) #convertimos la variable a factor
head(howell.centrado) #imprimimos las primeras observaciones
```

Luego ajustamos 7 modelos para la altura usando como predictores a la edad.centrada en forma de polinomios desde el grado 0 a 6.

```{r}
#generamos los modelos lineales bayesianos para la altura incorporando como predictor un polinomio grado cero hasta 6 con la edad.centrada
fit_1f_g0 <- stan_glm(altura ~ 1, data = howell.centrado, seed=SEED, refresh = 0)
fit_1f_g1 <- stan_glm(altura ~ poly(edad.centrada,1,raw=TRUE), data = howell.centrado, seed=SEED, refresh = 0)
fit_1f_g2 <- stan_glm(altura ~ poly(edad.centrada,2,raw=TRUE), data = howell.centrado, seed=SEED, refresh = 0)
fit_1f_g3 <- stan_glm(altura ~ poly(edad.centrada,3,raw=TRUE), data = howell.centrado, seed=SEED, refresh = 0)
fit_1f_g4 <- stan_glm(altura ~ poly(edad.centrada,4,raw=TRUE), data = howell.centrado, seed=SEED, refresh = 0)
fit_1f_g5 <- stan_glm(altura ~ poly(edad.centrada,5,raw=TRUE), data = howell.centrado, seed=SEED, refresh = 0)
fit_1f_g6 <- stan_glm(altura ~ poly(edad.centrada,6,raw=TRUE), data = howell.centrado, seed=SEED, refresh = 0)
```

Y a continuación mostramos el resumen de cada modelo:

```{r}
summary(fit_1f_g0) #mostramos el resumen del modelo
```

```{r}
summary(fit_1f_g1) #mostramos el resumen del modelo
```

```{r}
summary(fit_1f_g2) #mostramos el resumen del modelo
```

```{r}
summary(fit_1f_g3) #mostramos el resumen del modelo
```

```{r}
summary(fit_1f_g4) #mostramos el resumen del modelo
```

```{r}
summary(fit_1f_g5) #mostramos el resumen del modelo
```

```{r}
summary(fit_1f_g6) #mostramos el resumen del modelo
```

g) Para cada modelo en el inciso de arriba, genera gráficos que muestren las
predicciones junto con las bandas de predicción. 

Creamos las predicciones y gráficos con bandas de predicción considerando un intervalo del 89% a partir de funciones

```{r}
#función para calcular las predicciones de la posterior de los modelos para la altura (media y bandas del 89%)
df4plot<-function(model){
  edad.centrada<-tibble(seq(-40,70))
  colnames(edad.centrada)<-"edad.centrada"
  df<-as_tibble(posterior_predict(model, newdata=edad.centrada,seed=SEED)) %>%  #calculamos las predicciones con la posterior
  #cada fila es una simulación bajo una muestra distinta
  mutate(sample_id = 1:4000) %>% #creamos ID para cada
  pivot_longer(cols = 1:nrow(edad.centrada)) %>%
  mutate(name = fct_inorder(name)) %>% 
  group_by(name) %>% #name es la predicción de cada individuo (1-5)
  summarise(altura_mean=mean(value), #calcula media
            altura_median=median(value), #calcula mediana
            altura_low=quantile(value,.055), #intervalos del 89% de probabilidad
            altura_hi=quantile(value,.945))
df$edad.centrada<-as_vector(edad.centrada)
return(df)
}

#función que genera gráfico de predicciones para un modelo
plots<-function(df,points,title){
  g_points <-geom_point(data= points, aes(edad.centrada,altura),alpha=.1)
  g_1a<-df %>%
    ggplot(aes(edad.centrada,altura_mean)) + #graficamos peso vs altura_prom
    geom_ribbon(aes(ymin=altura_low,ymax=altura_hi),fill = "grey70",alpha=.3)+ #bandas de predicción
    geom_line(color="red") + #media de predicciones
    ggtitle(title)+
    ylab("altura")
  
  g_1a+g_points
}
```

```{r}
#guardamos predicciones
post_predict_1f_g0 <- df4plot(fit_1f_g0) 
post_predict_1f_g1 <- df4plot(fit_1f_g1)
post_predict_1f_g2 <- df4plot(fit_1f_g2)
post_predict_1f_g3 <- df4plot(fit_1f_g3)
post_predict_1f_g4 <- df4plot(fit_1f_g4)
post_predict_1f_g5 <- df4plot(fit_1f_g5)
post_predict_1f_g6 <- df4plot(fit_1f_g6)

#guardamos gráficos
g_g0<-plots(post_predict_1f_g0,howell.centrado,"Predicciones con polinomio grado 0 (I. 89%)")
g_g1<-plots(post_predict_1f_g1,howell.centrado,"Predicciones con polinomio grado 1 (I. 89%)")
g_g2<-plots(post_predict_1f_g2,howell.centrado,"Predicciones con polinomio grado 2 (I. 89%)")
g_g3<-plots(post_predict_1f_g3,howell.centrado,"Predicciones con polinomio grado 3 (I. 89%)")
g_g4<-plots(post_predict_1f_g4,howell.centrado,"Predicciones con polinomio grado 4 (I. 89%)")
g_g5<-plots(post_predict_1f_g5,howell.centrado,"Predicciones con polinomio grado 5 (I. 89%)")
g_g6<-plots(post_predict_1f_g6,howell.centrado,"Predicciones con polinomio grado 6 (I. 89%)")
```

Y presentamos los gráficos de cada modelo:

```{r}
g_g0 #muestra gráfica
```

```{r}
g_g1 #muestra gráfica
```
```{r}
g_g2 #muestra gráfica
```

```{r}
g_g3 #muestra gráfica
```

```{r}
g_g4 #muestra gráfica
```

```{r}
g_g5 #muestra gráfica
```

```{r}
g_g6 #muestra gráfica
```

h) Realiza una evaluación de los modelos resultantes con el criterio de
información que consideres más apropiado.

Para la evaluación de modelos nos basaremos en el criterio de información de loo ya que como vimos en el inciso d, el método loo() nos genera un diagnóstico del modelo y utiliza validación cruzada para evaluar su capacidad predictiva. A su vez, para una conclusión tomaremos en cuenta el principio de parsimonia en el que se prefiere el modelo más sencillo posible.

A continuación presentamos los diagnósticos:

```{r}
loo_1g_g0<-loo(fit_1f_g0) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1g_g0  #imprime resultados
```
```{r}
loo_1g_g1<-loo(fit_1f_g1) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1g_g1  #imprime resultados
```
```{r}
loo_1g_g2<-loo(fit_1f_g2) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1g_g2  #imprime resultados
```

```{r}
loo_1g_g3<-loo(fit_1f_g3) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1g_g3  #imprime resultados
```

```{r}
loo_1g_g4<-loo(fit_1f_g4) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1g_g4  #imprime resultados
```

```{r}
loo_1g_g5<-loo(fit_1f_g5) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1g_g5  #imprime resultados
```

```{r}
loo_1g_g6<-loo(fit_1f_g6) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1g_g6  #imprime resultados
```

El diagnóstico de todos los modelos que loo arrojó es que son buenos: "All Pareto k estimates are good (k < 0.5)." sólo con excepción del que utiliza un polinomio grado 6 en términos la edad.centrada como predictores pues en este caso indica ok: "All Pareto k estimates are ok (k < 0.7).". A continuación mostramos un resumen de los estadísticos de todos los modelos con loo:

```{r}
comparativo_loo_1g<-cbind(loo_1g_g0,loo_1g_g1,loo_1g_g2,loo_1g_g3,loo_1g_g4,loo_1g_g5,loo_1g_g6) #guarda comparativo
comparativo_loo_1g #imprime comparativo de modelos
```

En términos de la devianza (looic) los modelos que utilizan como predictores a los polinomios de grado 4 a 6 tienen la mejor capacidad predictiva ya que tienen una menor devianza respecto al resto de los modelos. Además, notamos que el error estándar de looic es de 33 aproximadamente en estos mismos modelos, por lo que no podríamos dar una conclusión definitiva sobre cuál de estos 3 predictores es el mejor con este criterio.

Para complementar el análisis, procederemos a obtener un comparativo en términos de la log-densidad predictiva con el método loo_compare().

```{r}
comparativo_diff_loo_1g<-loo_compare(loo_1g_g0,loo_1g_g1,loo_1g_g2,loo_1g_g3,loo_1g_g4,loo_1g_g5,loo_1g_g6) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_loo_1g  #imprime comparativo de modelos
```

Si bien estos resultados colocan en primer posición al modelo con el polinomio de grado 6 (mejor modelo), los modelos con polinomios de grado 4 y 5 como predictores tienen una log-densidad predictiva muy similar, además dado el error estándar de la diferencia que tienen es posible que para nuevas simulaciones de la posterior el  modelo 5 o 4 sea el mejor si usamos otra semilla. A continuación presentamos ejercicios donde validamos esto ():

```{r}
#volvemos a correr los modelos con otra senilla
fit_1f_g0_v2 <- stan_glm(altura ~ 1, data = howell.centrado, seed=SEED, refresh = 0)
loo_1f_g0_v2<-loo(fit_1f_g0_v2)
fit_1f_g1_v2 <- stan_glm(altura ~ poly(edad.centrada,1,raw=TRUE), data = howell.centrado, seed=SEED+1, refresh = 0)
loo_1f_g1_v2<-loo(fit_1f_g1_v2)
fit_1f_g2_v2 <- stan_glm(altura ~ poly(edad.centrada,2,raw=TRUE), data = howell.centrado, seed=SEED+1, refresh = 0)
loo_1f_g2_v2<-loo(fit_1f_g2_v2)
fit_1f_g3_v2 <- stan_glm(altura ~ poly(edad.centrada,3,raw=TRUE), data = howell.centrado, seed=SEED+1, refresh = 0)
loo_1f_g3_v2<-loo(fit_1f_g3_v2)
fit_1f_g4_v2 <- stan_glm(altura ~ poly(edad.centrada,4,raw=TRUE), data = howell.centrado, seed=SEED+1, refresh = 0)
loo_1f_g4_v2<-loo(fit_1f_g4_v2)
fit_1f_g5_v2 <- stan_glm(altura ~ poly(edad.centrada,5,raw=TRUE), data = howell.centrado, seed=SEED+1, refresh = 0)
loo_1f_g5_v2<-loo(fit_1f_g5_v2)
fit_1f_g6_v2 <- stan_glm(altura ~ poly(edad.centrada,6,raw=TRUE), data = howell.centrado, seed=SEED+1, refresh = 0)
loo_1f_g6_v2<-loo(fit_1f_g6_v2)
```

```{r}
comparativo_diff_loo_1g_v2<-loo_compare(loo_1f_g0_v2,loo_1f_g1_v2,loo_1f_g2_v2,loo_1f_g3_v2,loo_1f_g4_v2,loo_1f_g5_v2,loo_1f_g6_v2) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_loo_1g_v2 #imprime comparativo
```

En esta simulación, el modelo con polinomio grado 4 es el de mejor desempeño en relación a la log-densidad predictiva.

```{r}
#volvemos a correr los modelos con otra senilla
fit_1f_g0_v3 <- stan_glm(altura ~ 1, data = howell.centrado, seed=SEED, refresh = 0)
loo_1f_g0_v3<-loo(fit_1f_g0_v3)
fit_1f_g1_v3 <- stan_glm(altura ~ poly(edad.centrada,1,raw=TRUE), data = howell.centrado, seed=SEED-12, refresh = 0)
loo_1f_g1_v3<-loo(fit_1f_g1_v3)
fit_1f_g2_v3 <- stan_glm(altura ~ poly(edad.centrada,2,raw=TRUE), data = howell.centrado, seed=SEED-12, refresh = 0)
loo_1f_g2_v3<-loo(fit_1f_g2_v3)
fit_1f_g3_v3 <- stan_glm(altura ~ poly(edad.centrada,3,raw=TRUE), data = howell.centrado, seed=SEED-12, refresh = 0)
loo_1f_g3_v3<-loo(fit_1f_g3_v3)
fit_1f_g4_v3 <- stan_glm(altura ~ poly(edad.centrada,4,raw=TRUE), data = howell.centrado, seed=SEED-12, refresh = 0)
loo_1f_g4_v3<-loo(fit_1f_g4_v3)
fit_1f_g5_v3 <- stan_glm(altura ~ poly(edad.centrada,5,raw=TRUE), data = howell.centrado, seed=SEED-12, refresh = 0)
loo_1f_g5_v3<-loo(fit_1f_g5_v3)
fit_1f_g6_v3 <- stan_glm(altura ~ poly(edad.centrada,6,raw=TRUE), data = howell.centrado, seed=SEED-12, refresh = 0)
loo_1f_g6_v3<-loo(fit_1f_g6_v3)
```

```{r}
comparativo_diff_loo_1g_v3<-loo_compare(loo_1f_g0_v3,loo_1f_g1_v3,loo_1f_g2_v3,loo_1f_g3_v3,loo_1f_g4_v3,loo_1f_g5_v3,loo_1f_g6_v3) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_loo_1g_v3
```

De lo anterior, concluimos que la capacidad predictiva de los modelos con polinomios grado 4, 5 y 6 no tiene una diferencia significativa y por tanto, escogemos como el mejor modelo al que incorpora como predictores a la edad.centrada como un polinomio de grado 4 por el principio de parsimonia.

i) Ahora ajustaremos un polinomio de grado 6 pero incorporaremos distribuciones
previas mas restrictivas. Es decir, considera que $\beta_k \sim \mathsf{N}(0,
\sqrt{5})$ para toda $k.$ Nota que la desviación estándar es $\sqrt{5}.$ Evalúa
el criterio de información que utilizaste en el inciso anterior, y compara la
estimación de número efectivo de parámetros. ¿Por qué crees que sucede esto?

Primero calculamos el modelo con el polinomio grado 6 utilizando considerando que $\beta_k \sim \mathsf{N}(0,
\sqrt{5})$ para toda $k.$ y el resto de los parámetros con su default.

```{r}
fit_1i_g6 <- stan_glm(altura ~ poly(edad.centrada,6,raw=TRUE), #generamos el modelo lineal bayesiano
                      data = howell.centrado,
                      prior=normal(0, sqrt(5), autoscale = FALSE), #distribución previa para beta k, k>0
                      prior_intercept = normal(0, sqrt(5), autoscale = FALSE), #distribución previa para beta cero
                      seed=SEED,
                      refresh = 0)
print(fit_1i_g6) #imprimimos el objeto con el modelo
```

E imprimimos la distribución previa de los coeficientes del modelo, para validar que tanto el intercepto como los coeficientes tienen una distribución normal ($\mathsf{N}(0, \sqrt{5})$

```{r}
prior_summary(fit_1i_g6) #imprimimos el resumen con las priors propuestas que usa stan_glm
```

Ahora presentamos el resumen con los resultados de este modelo:

```{r}
summary(fit_1i_g6) #mostramos el resumen del modelo
```

Notamos que en este caso el intercepto tiene la mayor influencia sobre la predicción ya que el valor del coeficiente es muy alto en comparativa con el resto de los predictores que tienen un coeficiente menor a 2 en valor absoluto.

Graficamos para comparar cómo se ven las predicciones de la altura de ambos modelos bajo las observaciones de la muestra.

```{r}
post_predict_1i_g6 <- df4plot(fit_1i_g6) #guardamos las predicciones con el modelo grado 6 y las previas propuestas para Beta k

#guardamos gráficos
g_i_g6<-plots(post_predict_1i_g6,howell.centrado,"Predicciones con polinomio grado 6 v2 (I. 89%)")
```

```{r}
ggarrange(g_g6,g_i_g6,ncol = 1)
```
Y vemos que el segundo modelo está generando predicciones para la altura fuera de lo natural para edades en los extremos de la muestra. Esto se debe al efecto de las distribuciones previas propuestas para los coeficientes $\beta_k$ no permiten generar un buen ajuste respecto a los datos observados.

Posteriormente, realizamos el diagnóstico del modelo con el mismo criterio de información (usando el método loo):

```{r}
loo_1i_g6<-loo(fit_1i_g6) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1i_g6
```

En este caso, el diagnóstico arroja que el modelo es muy malo lo cual hace sentido con el gráfico que vimos arriba. Ahora procederemos a evaluar el criterio de información de loo que usamos en el inciso anterior generando un comparativo con los resultados de los modelos con polinomios de grado 6.

```{r}
comparativo_loo_1i<-cbind(loo_1g_g6,loo_1i_g6) #agrupa resultados loo
comparativo_loo_1i #imprime comparativo
```

Identificamos que el desempeño del modelo con la distribución por default tiene la mejor capacidad predictiva, dado que su devianza (looic) es claramente menor que la del polinomio con las distribuciones propuestas. En términos de la estimación del número efectivo de parámetros (p_loo) vemos que el modelo con polinomios grado 6 y default califica con 7.5 términos efectivos mientras que el modelo con las distribuciones previas propuestas para los coeficientes beta tienen valores exageradamente grandes, esto sugeriría que para poder brindar un mejor ajuste se tendrían que incorporar más parámetros al modelo dado que la desviación están de los coeficientes actual $\sqrt{5})$ es demasiado chica para que los coeficientes de los polinomios puedan tener valores más adecuados para las predicciones.

Por último sólo calculamos el comparativo de diferencia sobre la log-densidad predictiva.

```{r}
comparativo_diff_loo_1i<-loo_compare(loo_1g_g6,loo_1i_g6) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_loo_1i
```

Y observamos que la diferencia en términos de la log-densidad predictiva también es muy alta así como el error estándar asociado.

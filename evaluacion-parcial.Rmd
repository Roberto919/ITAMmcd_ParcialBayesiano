---
title: "Examen parcial - Primavera 2021"
author: Alfredo Garbuno Iñigo
output: html_document
---

**Entrega:** 

Enviar por correo electrónico una carpeta comprimida
(`equipo-xx.zip`) que incluya datos y codigo de solución a mas tardar el 23 de
Marzo antes de las 11:59pm (medianoche). El asunto deberá ser `[MB - 2021]
Parcial Equipo XX`, donde  reemplazarás `XX` con el codigo de tu equipo. No se
aceptarán entregas extemporáneas. Será mejor entregar un examen resuelto
parcialmente, que no entregar nada.

**Instrucciones:**
  
* Tus respuestas deben ser claras y debes explicar los resultados, incluye
también tus procedimientos/código de manera ordenada, y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas,
...).

* Las sesiones de dudas del Miércoles 17 de Marzo será completamente para
responder dudas del examen. Adicionalmente, en las sesiones del Martes 16 y
Jueves 18 se reservará una media hora para dudas (dependerá de la agenda cuál
será el momento más oportuno para abrir el espacio).

* No pueden compartir soluciones entre diferentes equipos.

* Al entregar este examen afirmas que el trabajo se realizó sólo con tu
compañeros de equipo. El material que utilizaste para apoyarte consistió de las
notas en clase (pdfs en Canvas), el codigo fuente de las notas en el repositorio
de Github.

* Al entregar estás dando tu consentimiento para que bajo sospecha y suficiente
evidencia de copia se anule tu evaluación.

**Ponderación:**

El examen está compuesto por tres apartados cuyo peso son los siguientes: 
1. Datos !Kung San (60%)
2. Datos Vinos     (25%)
3. Datos Nettle    (15%)


```{r setup, include=FALSE}

library(tidymodels)
library(tidyverse)
library(cmdstanr)
library(rstanarm)
library(bayesplot)
library(loo)

library(patchwork)
library(scales)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE,
                      fig.align = 'center', fig.width = 5, fig.height=3, cache = TRUE)
comma <- function(x) format(x, digits = 2, big.mark = ",")
theme_set(theme_linedraw())
```

## Datos: !Kung San.

Los datos que que tenemos en `Howell.txt` son datos parciales del censo para el
área de Dobe, en particular para la población de los [!Kung
San.](https://es.wikipedia.org/wiki/!Kung) Éstos fueron recopilados a partir de
entrevistas realizadas por Nancy Howell a finales de la década de 1960.

a ) Los pesos presentados a continuación se registraron en el censo !Kung, pero no
se registraron las alturas para estas personas. Proporciona predicciones para
las alturas e intervalos del 89% para cada uno de estos individuos basados en un
modelo de regresión lineal.

```{r}
peso<-tibble(peso = c(46.95, 43.72, 64.78, 32.59, 54.63))
peso
```


```{r}
datos1<-read_delim("howell.csv", delim = ";" ) #Cargamos los datos
```

```{r}
howell<-datos1
howell$genero<-factor(howell$genero)
glimpse(howell)
```


```{r}
#altura en cm
#eso en kg
#edad en años
#indicador si es hombre
summary(howell)
```

```{r}
m_1a <- lm(altura ~ peso, howell)
summary(m_1a)
```

```{r}
m_1a <- stan_glm(altura ~ peso, data = howell, refresh = 0)
#prior_summary(m_1a)
summary(m_1a)
```


### Predicciones usando `stan_glm`

```{r }
new <- data.frame(peso)
y_point_pred <- predict(m_1a, newdata=new)
y_point_pred
```

```{r }
y_linpred <- posterior_linpred(m_1a, newdata=new)
summary(y_linpred)
```

```{r }
y_pred <- posterior_predict(m_1a, newdata=new)
summary(y_pred)
```

Para poder dar una interpretación más sencilla al modelo lineal para predecir la altura, estandarizaremos las variables numéricas centrando al rededor de su media:

```{r, eval = FALSE}
howell<-howell %>%
  mutate(peso.centrado = peso-mean(peso))
howell
```

Una persona promedio con peso y edad promedio tendría una altura de 138 cm, cuando la persona tiene un punto adicional sobre el peso promedio, la altura aumenta 1.76cm.

```{r}
m_1a <- lm(altura ~ peso.centrado, howell)
summary(m_1a)
```

```{r}
m_1a$coefficients
```

Las predicciones para las alturas son:


b) Ajusta un modelo lineal para personas menores de 18 años de edad utilizando
como predictores la `edad` y el `peso`. Interpreta los coeficientes que resultan
del modelo. Si consideras necesario centra los valores de las variables
predictoras.

```{r}
menores_edad<-datos1 %>% filter(edad < 18)
menores_edad
```
Para poder dar una interpretación más sencilla al modelo lineal para predecir la altura, centraremos las variables numéricas centrando al rededor de su media:

```{r, eval = FALSE}
menores_edad<-menores_edad %>%
  mutate(peso.centrado = peso-mean(peso),
         edad.centrado = edad-mean(edad))
menores_edad
```
```{r}
m_1b <- lm(altura ~ peso.centrado+ edad.centrado, menores_edad)
summary(m_1b)
```

```{r}
m_1b <- stan_glm(altura ~ peso.centrado+ edad.centrado, data = menores_edad, refresh = 0)
#prior_summary(m_2a)
summary(m_1b)
```

c) Para el modelo resultante, haz gráficos que muestren la relación de la
variable objetivo con los predictores. De igual forma, incorpora en la
visualización la respuesta del modelo lineal junto con intervalos de predicción
al 89\% y 97\%, de tal forma que incorpores la incertidumbre que se ha
cuantificado en tu gráfico.

```{r}
menores_edad %>%
  ggplot(aes(x=peso.centrado,y=altura)) +
  geom_point()
```
```{r}
menores_edad %>%
  ggplot(aes(x=edad.centrado,y=altura)) +
  geom_point()
```


d) Supongamos que tenemos una amiga que es experta en
[alometría](https://es.wikipedia.org/wiki/Alometr%C3%ADa) y les menciona que el
peso es suficiente, pero que se debería de incorporar en términos de una escala
logarítmica. Ajusta el modelo con todos las observaciones y compara con el
modelo del inciso a) y un modelo adicional que sólo incorpora el `peso`. ¿Cuál
parece tener mejor capacidad predictiva?

```{r}
m_1d <- stan_glm(altura ~ log(peso.centrado), data = howell, refresh = 0)
#prior_summary(m_1a)
summary(m_1d)
```


e) ¿Cómo interpretas los coeficientes del mejor modelo del inciso `d`?

```{r}

```


f) Ahora estudiaremos el efecto de la distribución previa. Para esto
consideraremos. La variable de `edad` centrada y probaremos distintos polinomios
como predictores. Consideraremos potencias desde 0 hasta términos de grado 6.
Ajusta esta colección de posibles modelos.

```{r}
poly(edad.centrado,2,raw=TRUE)
```


g) Para cada modelo en el inciso de arriba, genera gráficos que muestren las
predicciones junto con las bandas de predicción.



h) Realiza una evaluación de los modelos resultantes con el criterio de
información que consideres más apropiado.



i) Ahora ajustaremos un polinomio de grado 6 pero incorporaremos distribuciones
previas mas restrictivas. Es decir, considera que $\beta_k \sim \mathsf{N}(0,
\sqrt{5})$ para toda $k.$ Nota que la desviación estandar es $\sqrt{5}.$ Evalúa
el criterio de información que utlizaste en el inciso anterior, y compara la
estimación de número efectivo de parámetros. ¿Por qué crees que sucede esto?





## Datos: Vinos.

Consideremos el conjunto de datos en `vinos.txt`. Estos datos son evaluaciones
de 20 vinos diferentes, tanto franceses y estadounidenses, realizadas por 9
jueces (también, franceses y estadounidenses) diferentes. El objetivo de este
ejercicio es modelar el `score`, la calificación subjetiva que cada juez asigna
a cada vino. Recomiendo centrarlo para el ajuste de los modelos.


### Lectura de los datos
```{r}
## Definición de semilla
SEED <- 1234

## Lectura de los datos
data_vinos <- read.table("vinos.txt", sep=";", header=TRUE)

## Creando columna con variable "score" centrada
data_vinos <- data_vinos %>%
  mutate(
    score_c = score - mean(score),
    judge = ifelse(judge.amer == 1, paste0(judge, " (AM)"), paste0(judge, " (FR)")),
    wine = ifelse(wine.amer == 1, paste0(wine, " (AM)"), paste0(wine, " (FR)")),
  ) %>% 
  mutate(
    wine = ifelse(flight == "white", paste0(wine, " - white"), paste0(wine, " - red")),
  )

data_vinos
```





### Exploración inicial de los datos
```{r}
#### Explorando predictores
print("Nombres de los jueces en el set de datos: ")
unique(data_vinos$judge)
cat("\n")

print("Conteo de jueces por nacionalidad: ")
paste0("Franceses: ", length(grep("(FR)", unique(data_vinos$judge))))
paste0("Americanos: ", length(grep("(AM)", unique(data_vinos$judge))))
cat("\n")

print("Vinos incorporados en la competencia: ")
unique(data_vinos$wine)
cat("\n")

print("Conteo de vinos por nacionalidad: ")
paste0("Franceses: ", length(grep("(FR)", unique(data_vinos$wine))))
paste0("Americanos: ", length(grep("(AM)", unique(data_vinos$wine))))
cat("\n")

print("Tipos de vinos en la competencia: ")
unique(data_vinos$flight)
cat("\n")


#### Explorando la distribución de scores
bx1 <- data_vinos %>%
    ggplot(
        aes(score)
    ) + geom_histogram(fill="orange") +
  labs(title="Score original")

bx2 <- data_vinos %>%
    ggplot(
        aes(score_c)
    ) + geom_histogram(fill="green") +
  labs(title="Score ajustado")

bx1 + bx2
```



### Evaluación del comportamiento de los datos

```{r}
## Exploración de calificaciones según los jueces (judge)
data_vinos %>% 
  group_by(judge) %>% 
  summarise(
    mean = mean(score_c),
    n(),
    max(score_c),
    min(score_c)
  ) %>% 
  arrange(mean)
```

```{r}
## Exploración de calificaciones según el vino (wine)
data_vinos %>% 
  group_by(wine) %>% 
  summarise(
    mean = mean(score_c),
    n(),
    max(score_c),
    min(score_c)
  ) %>% 
  arrange(desc(mean))
```

```{r}
## Exploración de calificaciones según el tipo de vino (flight)
data_vinos %>%
  group_by(flight) %>%
  summarise(
    mean(score_c),
    n(),
    max(score_c),
    min(score_c)
  )

t.test(
  filter(data_vinos, flight == "red")$score, filter(data_vinos, flight != "red")$score
)
```
**Aquí podemos observar que no hay una diferencia relevante en las calificaciones según el tipo de vino (rojo o blanco).**



```{r}
## Exploración de las calificaciones por el origen del vino (wine.amer)
data_vinos %>%
  group_by(wine.amer) %>%
  summarise(
    n(),
    mean(score),
    min(score),
    max(score)
  )

t.test(filter(data_vinos, wine.amer == 0)$score, filter(data_vinos, wine.amer == 1)$score)
```
**Aquí vemos que tampoco hay una diferencia muy grande en las calificaciones según el origen del vino.**



```{r}
## Evaluar si hay alguna diferencia importante entre los vinos según origen y tipo (wine.amer + flight)
data_vinos %>%
  group_by(wine.amer, flight) %>%
  summarise(
    n(),
    mean(score),
    min(score),
    max(score)
  )
```



```{r}
## Evaluando diferencias en vinos rojos dependiendo de su origen.
amer_red <- data.frame(
  score = filter(data_vinos, wine.amer == 1, flight == "red")$score,
  type = "rojo_americano"
)

nonamer_red <- data.frame(
  score = filter(data_vinos, wine.amer == 0, flight == "red")$score,
  type = "rojo_no_americano"
)

rbind(amer_red, nonamer_red) %>% 
  ggplot(
    aes(x=score, color=type)
  ) + geom_histogram(fill="white") + 
  labs(title="Comparación de vinos (rojos) según su origen")
  

t.test(filter(data_vinos, wine.amer == 1, flight == "red")$score, filter(data_vinos, wine.amer == 0, flight == "red")$score)
```
**El resultado de la prueba Welch indica que sí hay una diferencia estadísticamente significativa (asumiendo un valor-p límite de 0.05) en el score de los vinos rojos dependiendo de su origen.**



```{r}
## Evaluando diferencias en vinos blancos dependiendo de su origen.
amer_white <- data.frame(
  score = filter(data_vinos, wine.amer == 1, flight == "white")$score,
  type = "blanco_americano"
)

nonamer_white <- data.frame(
  score = filter(data_vinos, wine.amer == 0, flight == "white")$score,
  type = "blanco_no_americano"
)

rbind(amer_white, nonamer_white) %>% 
  ggplot(
    aes(x=score, color=type)
  ) + geom_histogram(fill="white") + 
  labs(title="Comparación de vinos (blancos) según su origen")
  

t.test(filter(data_vinos, wine.amer == 1, flight == "white")$score, filter(data_vinos, wine.amer == 0, flight == "white")$score)
```
**Aquí obsservamos que no hay una diferencia estadísticamente significativa en los vinos blancos dependiendo de su origen.**



```{r}
## Diferencia en las calificaciones según el origen del juez
data_vinos %>%
  group_by(judge.amer) %>%
  summarise(
    n(),
    mean(score),
    min(score),
    max(score)
  )

amer_judge <- filter(data_vinos, judge.amer == 1)$score
nonamer_judge <- filter(data_vinos, judge.amer == 0)$score

t.test(amer_judge, nonamer_judge)
```
**Estos resultados nos sugieren que no hay una diferencia importante entre los scores de jueces americanos y no americanos.**



a) En este inciso, sólo considera la variación entre jueces y
vinos. Ajusta un modelo de regresión lineal utilizando estos predictores.
Justifica tu distribución _a priori_. ¿Cómo interpretas la variación entre
jueces individuales y vinos individuales? ¿Notas algún patrón (puedes utilizar
`mcmc_areas`)? ¿Qué jueces dieron las calificaciones más altas / más bajas? ¿Qué
vinos fueron calificados como peores / mejores en promedio?


```{r}

## Ajuste de modelo
m_2a <- stan_glm(score_c ~ judge + wine,
                 prior=normal(0, 0.5),
                 data=data_vinos,
                 seed=SEED,
                 refresh = 0,
               )
# summary(m_2a)
print(m_2a)
```
**Para este problema se optó por usar una distribución _a priori_ normal con media en 0 y desviación estándar 0.5**


```{r}
mcmc_areas(m_2a)
```
**Esta visualización nos permite ver la estimación de los intervalos posterior, con la cual podemos hacer las siguientes observaciones:**
**1. Los jueces con una desviación positiva fueron menos estrictos al momento de dar una calificación que los juecs que muestran una desviación negativa. Por lo tanto, podemos observar que los jueces más estrictos fueron Jean-M Cardepat y Robert Hodgson.**
**2. Similar al tema de los jueces, los vinos que tuvieron una desviación negativa fueron los más penalizados, mientras que los que mostraron una desviación positiva fueron los más reconocidos. A diferencia del tema de los jueces, vemos un comportamiento más consistente en los intervalos de los vinos.**



b) Ajusta con la previa _default_ en `stan_glm`. Después, ajusta de nuevo el
modelo con una distribución a priori regularizada (incorpora `prior = hs()` en
las opciones). ¿Que observas al comparar la $R^2$-Bayesiana de ambos modelos?
¿Cómo explicas éste comportamiento? Por otro lado, calcula la capacidad
predictiva por medio de `loo` o `waic` (el que tu elijas) en ambos y describe lo
que observas en el estadistico que describe el número efectivo de parámetros.
¿Cómo justificas este comportamiento? ¿Cómo concilias lo observado en la $R^2_B$
y la comparación de devianza entre ambas posibilidades?

```{r}
## Ajustando con previa _default_
m_2b1 <- stan_glm(
  score ~ judge + wine,
  data=data_vinos
)

print(m_2b1)

bR2_m_2b1 <- bayes_R2(m_2b1)

mcmc_hist(
  data.frame(bR2_m_2b1),
  binwidth=0.01
)  +
  xlab('Bayesian R2 con previa _default_') +
  geom_vline(xintercept=median(bR2_m_2b1))
```



```{r}
## Ajustando con distribución a priori regularizada
m_2b2 <- stan_glm(
  score ~ judge + wine,
  data=data_vinos,
  prior=hs()
)

print(m_2b2)

bR2_m_2b2 <- bayes_R2(m_2b2)

mcmc_hist(
  data.frame(bR2_m_2b2),
  binwidth=0.01
)  +
  xlab('Bayesian R2 con distribución a priori regularizada') +
  geom_vline(xintercept=median(bR2_m_2b2))
```

**Al copmarar la R^2-Bayesiana podemos observar que...**

```{r}
waic_m_2b1 <- waic(m_2b1)
waic_m_2b2 <- waic(m_2b2)

comp_waic <- cbind(waic_m_2b1, waic_m_2b2)
comp_waic
```
**Al observar los resultados de la prueba waic, pordemos notar que...**


c) Ahora considera como predictores `flight`(el tipo de vino), `wine.amer` (de
dónde proviene), y `judge.amer` (indicador si el juez es americano). Para este
inciso no incluyas las variables de los casos anteriores. De igual manera,
justifica la selección de distribución previa que utilizas. ¿Cómo se relacionan
estas estimaciones con lo que observaste en el inciso `a`?

```{r}
## Ajuste de modelo
m_2c <- stan_glm(score_c ~ flight + wine.amer + judge.amer,
                 prior=normal(0, 0.5),
                 data=data_vinos,
                 seed=SEED,
                 refresh = 0,
               )
# summary(m_2a)
print(m_2c)
```
**Para este ejercicio, se optó por utilizar una distribución previa de ...**


```{r}
mcmc_areas(m_2c)
```

**A partir de la gráfica de distribucioines posterior podemos observar lo siguiente:**
**1. No hay una diferencia relevante en el score dado el tipo de vino (rojo o blanco).**
**2. Los jueces americanos tienden a ser un poco menos estrictos que los no americanos.**
**3. Los vinos americanos tienden a ser más peores calificados que los no americanos.**


d) Ahora considera todas las posibles interacciones de dos términos con las tres
variables de arriba. Explica lo que significa cada término e interpreta los
coeficientes. ¿Cómo se relacionan estos resultados con los del inciso `a` de
esta sección?

```{r}
## Ajuste de modelo
m_2d <- stan_glm(score_c ~ flight + wine.amer + judge.amer + flight:wine.amer + flight:judge.amer + wine.amer:judge.amer,
                 prior=normal(0, 0.5),
                 data=data_vinos,
                 seed=SEED,
                 refresh = 0,
               )
# summary(m_2a)
print(m_2d)

mcmc_areas(m_2d)
```

**A partir de esta última gráfica de distribuciones posteriores, podemos hacer las siguientes observaciones:**
**1. **


### Datos:

Utiliza los datos en `nettle.txt` para evaluar la hipótesis de que la diversidad
lingüística es producto de la seguridad alimentaria. Los datos contienen mediciones para:

1) `country`: Nombre del país.
2) `num.lang`: Número de lenguajes identificados en dicho país.
3) `area`: Area medida en kilómetros cuadrados.
4) `k.pop`: Población en miles.
5) `num.stations`: Número de estaciones que proveen las siguientes.
6) `mean.growing.season`: Duración promedio de la temporada de cosecha, medida
en meses.
7) `sd.growing.season`: Desviación estándar de la duración de la
temporada de cosecha, medidad en meses.

La idea es que, en las ecologías productivas, las personas no necesitan grandes
redes sociales para protegerse contra el riesgo de escasez de alimentos. Esto
significa que los grupos culturales pueden ser más pequeños y más
autosuficientes, lo que lleva a más idiomas per cápita. Utiliza el número de
idiomas per cápita como resultado:

```{r, eval = FALSE}
data <- read.delim("nettle.txt",sep = ";")
data <- data %>%
    mutate(leng.per.cap = num.leng/k.pob)%>%
    mutate(log.leng.per.cap = log(leng.per.cap))%>%
    mutate(log.area = log(area))%>%
    mutate(log.k.pop = log(k.pob))
data
```

Utilice el logaritmo de esta nueva variable como el objetivo de un modelo de
regresión. Este problema tiene un final abierto, lo que les permite decidir cómo
abordar las hipótesis y las predicciones inciertas que proporciona el modelo. Si
creen que necesita usar WAIC/LOO en cualquier momento, háganlo. Si creen que necesitan
cierta distribución previa, argumenten por ella. Si creen que necesitan mostrar
las predicciones de cierta manera, háganlo. Traten de evaluar honestamente
los efectos principales de la temporada media de crecimiento
(`mean.growing.season`) y la desviación de la temporada de crecimiento
(`sd.growing.season`), así como su interacción.

### Respuesta:

Para este análisis, se busca explicar los efectos  principales de la temporada media de crecimiento
(`mean.growing.season`) y la desviación de la temporada de crecimiento
(`sd.growing.season`), así como su interacción en el desarrollo de lenguajes en distintas poblaciones.


Primero comenzamos con un breve analisis exploratiori ode diferentes variabes para entender la relación entre ellas.

Analisis Exploratiorio
```{r,eval = FALSE}
library(psych)
pairs.panels(data[,3:11],
            method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
             )
boxplot(data$mean.growing.season)
boxplot(data$sd.growing.season)
boxplot(data$log.leng.per.cap)


```
Depués comenzamos a desarrollar diferentes modelos que expliquen nuestra variable independiente "log.leng.per.cap". La estrategia es la siguiente, crear un modelo base que contenga `mean.growing.season`,`sd.growing.season`, su interacción y `log.area`. Además, se agregarán a este modelo base otras variables que se encuentran dentro de la base de datos que son `log.k.pop` y `num.stations`. El objetivo es crear diferentes modelos, evaluar su capacidad predictiva por medio de WAIC/LOO y seleccionar el mejor.




```{r,eval = FALSE}

###Basline Model: Only  Mean, SD, Interaction, Area
model1 <- stan_glm(log.leng.per.cap~mean.growing.season+sd.growing.season+mean.growing.season*sd.growing.season+log.area,
                  data = data,
                  prior_intercept = default_prior_intercept("normal"),
                  prior = default_prior_coef("normal"),
                  seed = 108727, refresh = 0)
###Model 2 : Baseline Model + numstations k.pop
model2 <-stan_glm(log.leng.per.cap~mean.growing.season+sd.growing.season+mean.growing.season*sd.growing.season+log.area+num.stations+log.k.pop,
                  data = data,
                  prior_intercept = default_prior_intercept("normal"),
                  prior = default_prior_coef("normal"),
                  seed = 108727, refresh = 0)
###Model 3 : Baseline Model + numstations
model3 <-stan_glm(log.leng.per.cap~mean.growing.season+sd.growing.season+mean.growing.season*sd.growing.season+log.area+num.stations,
                  data = data,
                  prior_intercept = default_prior_intercept("normal"),
                  prior = default_prior_coef("normal"),
                  seed = 108727, refresh = 0)

###Model 4 : Baseline Model + kpop
model4 <-stan_glm(log.leng.per.cap~mean.growing.season+sd.growing.season+mean.growing.season*sd.growing.season+log.area+log.k.pop,
                  data = data,
                 prior_intercept = default_prior_intercept("normal"),
                  prior = default_prior_coef("normal"),
                  seed = 108727, refresh = 0)


```

```{r,eval = FALSE}
print(model1)
print(model2)
print(model3)
print(model4)

```
```{r,eval = FALSE}
loo1<-loo(model1)
loo2<-loo(model2)
loo3<-loo(model3)
loo4<-loo(model4)


waic1<-waic(model1)
waic2<-waic(model2)
waic3<-waic(model3)
waic4<-waic(model4)

loo_compare(loo1,loo2,loo3,loo4)
loo_compare(waic1,waic2,waic3,waic4)
```
Además de crear estos modelos, relizamos unas transformaciones a las variables `mean.growing.season`,`sd.growing.season` para centrarlas en su media. Con esto obtenemos las nuevas variables `centered.mean.growing.season`,`centered.sd.growing.season`. En este caso, la interpretación de los coeficientes es un poco distinta.


En este caso, las variables `mean.growing.season` y `sd.growing.season` son mayores o iguales a 0.


```{r,eval=FALSE}

data_centered = data %>%
              mutate(centered.mean.growing.season= mean.growing.season - mean(mean.growing.season))%>%
              mutate(centered.sd.growing.season= sd.growing.season - mean(sd.growing.season))

###Basline Model: Only  Mean, SD, Interaction, Area
model_centered_1 <- stan_glm(log.leng.per.cap~centered.mean.growing.season+centered.sd.growing.season+centered.mean.growing.season*centered.sd.growing.season+log.area,
                              data = data_centered,
                              prior_intercept = default_prior_intercept("normal"),
                             prior = default_prior_coef("normal"),
                              seed = 108727, refresh = 0)

### Model centered 2: Basline + numstatiosn + logpop
model_centered_2 <- stan_glm(log.leng.per.cap~centered.mean.growing.season+centered.sd.growing.season+centered.mean.growing.season*centered.sd.growing.season+log.area+num.stations+log.k.pop,
                              data = data_centered,
                              prior_intercept = default_prior_intercept("normal"),
                             prior = default_prior_coef("normal"),
                              seed = 108727, refresh = 0)

### Model centered 3: Basline + numstatiosn
model_centered_3 <- stan_glm(log.leng.per.cap~centered.mean.growing.season+centered.sd.growing.season+centered.mean.growing.season*centered.sd.growing.season+log.area+num.stations,
                              data = data_centered,
                              prior_intercept = default_prior_intercept("normal"),
                             prior = default_prior_coef("normal"),
                              seed = 108727, refresh = 0)

### Model centered 4: Basline  + logpop
model_centered_4 <- stan_glm(log.leng.per.cap~centered.mean.growing.season+centered.sd.growing.season+centered.mean.growing.season*centered.sd.growing.season+log.area+log.k.pop,
                              data = data_centered,
                              prior_intercept = default_prior_intercept("normal"),
                             prior = default_prior_coef("normal"),
                              seed = 108727, refresh = 0)

### Model centered 4: Basline  + logpop + noncentered interactions
#model_centered_5 <- stan_glm(log.leng.per.cap~centered.mean.growing.season+centered.sd.growing.season+mean.growing.season*s#d.growing.season+log.area+log.k.pop,
#                              data = data_centered,
#                              prior_intercept = default_prior_intercept("normal"),
#                              prior = default_prior_coef("normal"),
#                              prior_aux = NULL,
#                              seed = 108727, refresh = 0)
```

```{r,eval = FALSE}
print(model_centered_1)
print(model_centered_2)
print(model_centered_3)
print(model_centered_4)
#print(model_centered_5)


```

```{r,eval = FALSE}
loo1_centered<-loo(model_centered_1)
loo2_centered<-loo(model_centered_2)
loo3_centered<-loo(model_centered_3)
loo4_centered<-loo(model_centered_4)
#loo5_centered<-loo(model_centered_5)

waic1_centered<-waic(model_centered_1)
waic2_centered<-waic(model_centered_2)
waic3_centered<-waic(model_centered_3)
waic4_centered<-waic(model_centered_4)
#waic5_centered<-waic(model_centered_5)


loo_compare(loo1_centered,loo2_centered,loo3_centered,loo4_centered)
loo_compare(waic1_centered,waic2_centered,waic3_centered,waic4_centered)
```

```{r,eval = FALSE}
loo_compare(loo1,loo2,loo3,loo4,loo1_centered,loo2_centered,loo3_centered,loo4_centered)

loo_compare(waic1,waic2,waic3,waic4,waic1_centered,waic2_centered,waic3_centered,waic4_centered)
```

a) Evalúe la hipótesis de que la diversidad lingüística, medida por
`log(lang.per.cap)`, está asociada positivamente con la duración promedio de la
temporada de crecimiento, `mean.growing.season`. Considera tambíen  `log(area)`
en tu modelo (no como una interacción). Interpreten sus resultados.


```{r, eval = FALSE}

ggplot(data = data_centered, aes(x = centered.mean.growing.season, y = log.leng.per.cap))  +
    geom_abline(data = as_tibble(model_centered_4) %>% sample_frac(.2),
                aes(slope = centered.mean.growing.season, intercept = `(Intercept)`),
                color = 'grey', alpha = .4) +
    geom_abline(slope = coef(model_centered_4)[2], intercept = coef(model_centered_4)[1], color = 'salmon') +
    geom_point()

posterior_vs_prior(model_centered_4,pars= c("centered.mean.growing.season"))

as_tibble(model_centered_4)%>%
    ggplot(aes(x = centered.mean.growing.season)) +
        geom_histogram() +
        geom_vline(xintercept = coef(model_centered_4)[2], lty = 2) +
        xlab("Valor del Coeficiente")+
        ggtitle("Distribución posterior del Coeficiente")
```
```{r, eval = FALSE}
posterior_interval(model_centered_4,pars= c("centered.mean.growing.season"))
```




b) Ahora evalúen la hipótesis de que la diversidad lingüística está asociada
negativamente con la desviación estándar de la duración de la temporada de
crecimiento. Esta hipótesis se deriva de la incertidumbre en la cosecha que
favorece la seguridad social a través de redes sociales más amplias y, por lo
tanto, menos idiomas. Nuevamente, considere `log(area)` como una covariable (no
una interacción). Interpreten sus resultados.


```{r, eval = FALSE}

ggplot(data = data_centered, aes(x = sd.growing.season, y = log.leng.per.cap))  +
    geom_abline(data = as_tibble(model1) %>% sample_frac(.2),
                aes(slope = sd.growing.season, intercept = `(Intercept)`),
                color = 'grey', alpha = .4) +
    geom_abline(slope = coef(model1)[3], intercept = coef(model1)[1], color = 'salmon') +
    geom_point()

posterior_vs_prior(model1,pars= c("sd.growing.season"))

as_tibble(model1)%>%
    ggplot(aes(x = sd.growing.season)) +
        geom_histogram() +
        geom_vline(xintercept = coef(model1)[3], lty = 2) +
        xlab("Valor del Coeficiente")+
        ggtitle("Distribución posterior del Coeficiente")
```
```{r, eval = FALSE}
posterior_interval(model_centered_4,prob = .6, pars= c("centered.sd.growing.season"))
posterior_interval(model_centered_4,pars= c("centered.sd.growing.season"))
```

c) Finalmente, evalúen la hipótesis de que `mean.growing.season` y
`sd.growing.season` interactúan para reducir sinérgicamente la diversidad del
lenguaje. La idea es que, en naciones con temporadas de cultivo en promedio más
largas, la alta variación hace que el almacenamiento y la redistribución sean
aún más importantes de lo que serían de otra manera. De esa manera, las personas
pueden cooperar para preservar y proteger las ganancias inesperadas que se
utilizarán durante las sequías.

---
title: "Examen parcial - Primavera 2021"
author: Alfredo Garbuno Iñigo
output: html_document
---

**Entrega:** 

Enviar por correo electrónico una carpeta comprimida
(`equipo-xx.zip`) que incluya datos y codigo de solución a mas tardar el 23 de
Marzo antes de las 11:59pm (medianoche). El asunto deberá ser `[MB - 2021]
Parcial Equipo XX`, donde  reemplazarás `XX` con el codigo de tu equipo. No se
aceptarán entregas extemporáneas. Será mejor entregar un examen resuelto
parcialmente, que no entregar nada.

**Instrucciones:**
  
* Tus respuestas deben ser claras y debes explicar los resultados, incluye
también tus procedimientos/código de manera ordenada, y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas,
...).

* Las sesiones de dudas del Miércoles 17 de Marzo será completamente para
responder dudas del examen. Adicionalmente, en las sesiones del Martes 16 y
Jueves 18 se reservará una media hora para dudas (dependerá de la agenda cuál
será el momento más oportuno para abrir el espacio).

* No pueden compartir soluciones entre diferentes equipos.

* Al entregar este examen afirmas que el trabajo se realizó sólo con tu
compañeros de equipo. El material que utilizaste para apoyarte consistió de las
notas en clase (pdfs en Canvas), el codigo fuente de las notas en el repositorio
de Github.

* Al entregar estás dando tu consentimiento para que bajo sospecha y suficiente
evidencia de copia se anule tu evaluación.

**Ponderación:**

El examen está compuesto por tres apartados cuyo peso son los siguientes: 
1. Datos !Kung San (60%)
2. Datos Vinos     (25%)
3. Datos Nettle    (15%)


```{r setup, include=FALSE}
library(tidymodels)
library(tidyverse)
library(cmdstanr)
library(rstanarm)
library(bayesplot)
library(loo)
library(patchwork)
library(scales)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE, 
                      fig.align = 'center', fig.width = 5, fig.height=3, cache = TRUE)
comma <- function(x) format(x, digits = 2, big.mark = ",")
theme_set(theme_linedraw())
```

## Datos: !Kung San.

Los datos que tenemos en `Howell.csv` son datos parciales del censo para el
área de Dobe, en particular para la población de los [!Kung
San.](https://es.wikipedia.org/wiki/!Kung) Éstos fueron recopilados a partir de
entrevistas realizadas por Nancy Howell a finales de la década de 1960.

a ) Los pesos presentados a continuación se registraron en el censo !Kung, pero no
se registraron las alturas para estas personas. Proporciona predicciones para
las alturas e intervalos del 89% para cada uno de estos individuos basados en un
modelo de regresión lineal.

```{r}
pesos<-tibble(peso = c(46.95, 43.72, 64.78, 32.59, 54.63))
pesos
```


Dado que queremos generar predicciones para las alturas y sólo tenemos los pesos, decidimos utilizar un modelo de regresión lineal bajo un enfoque bayesiano utilizando como variable predictora el peso.

```{r}
datos1<-read_delim("howell.csv", delim = ";" ) #Cargamos los datos
```

Para lo cual, primero haremos un análisis exploratorio a los datos parciales del censo para conocer más al respecto.

```{r}
howell<-datos1
head(howell)
```

Primero identificamos que nuestro conjunto de datos contiene únicamente 544 observaciones y 4 columnas. Donde la variable a predecir (altura) se encuentra en centímetros, el peso en kg, la edad en años y el género es un indicador de sexo masculino cuando toma el valor de 1.

```{r}
howell$genero<-factor(howell$genero) #Convertimos la variable a factor
summary(howell)
```

Después vemos que la muestra contiene a personas de 0 a 88 años de edad con pesos que van de los 4 kilos a los 63. Sin embargo, llama nuestra atención que aunque la mediana de altura está alrededor de 1.5 metros, mediana de la edad corresponde a una persona adulta con 27 años de edad y 40 kg de peso. Lo anterior en el sentido de que si se tratara de una muestra en una población mexicana los pesos de los adultos serían más altos así como las alturas dado que en México somos una población donde la mayoría tiene sobrepeso u obesidad. Por ello, concluimos que no tenemos suficiente información preliminar para que podamos proponer distribuciones previas para los parámetros del modelo. De lo anterior, utilizamos el default de la distribución que proporciona stan_glm (una distribución poco informativa) para no sesgar nuestro modelo:

```{r}
SEED <- 2021
set.seed(SEED)
fit_1a <- stan_glm(altura ~ peso, data = howell, seed=SEED, refresh = 0)
print(fit_1a)
```

Lo anterior nos dice que la predicción es precisa hasta más / menos 9.4 unidades que en este caso son centímetros.

```{r}
prior_summary(fit_1a)
```

Como comentamos, la distribución previa que utilizamos es la de default la cual parte de nuestra muestra de 544 observaciones. Esto es, para el intercepto utiliza la altura media de nuestros datos con una desviación estándar de 2.5 para el intercepto y el peso.

```{r}
summary(fit_1a)
```


Ahora utilizaremos la función posterior_predict() para calcular las predicciones de altura con base en los pesos de los 5 individuos bajo nuestro modelo de regresión ya que considera la incertidumbre asociada a los coeficientes del modelo y al error observacional (epsilon) incorporando sigma o el error aditivo.

```{r}
post_predict_1a<-as_tibble(posterior_predict(fit_1a, newdata=pesos,seed=SEED)) %>% 
  #cada fila es una simulación bajo una muestra distinta
  mutate(sample_id = 1:4000) %>% #creamos ID para cada
  pivot_longer(cols = 1:5) %>%
  mutate(name = fct_inorder(name)) %>% 
  group_by(name) %>% #name la predicción de cada individuo (1-5)
  summarise(altura_mean=mean(value), 
            altura_median=median(value),
            altura_low=quantile(value,.055), #intervalos del 89% de probabilidad
            altura_hi=quantile(value,.945))

post_predict_1a<-post_predict_1a %>%
  mutate(pesos)

post_predict_1a %>% mutate_if(is.numeric, ~round(., 1))
```

```{r}
g_1a<-post_predict_1a %>%
  ggplot(aes(peso,altura_mean)) +
  geom_ribbon(aes(ymin=altura_low,ymax=altura_hi),alpha=.3)+
  geom_line(color="red") + #sin_lineas +
  geom_jitter(data=howell %>% filter(peso>30),
              aes(peso,altura),
              height = 0, width = 0.01, colour="black")
g_1a
```

Son las predicciones de la distribución posterior considerando únicamente a partir de la variación de los coeficientes alrededor de la media

```{r}
post_linpredt_1a <- as_tibble(posterior_linpred(fit_1a, newdata = pesos, seed=SEED)) %>% 
  mutate(sample_id = 1:4000) %>% 
  pivot_longer(cols = 1:5) %>% 
  mutate(name = fct_inorder(name)) %>% 
  group_by(name) %>% 
  summarise(altura_mean = mean(value),
            altura_median = median(value), 
            altura_low = quantile(value, .055), 
            altura_hi = quantile(value, .945))  
post_linpredt_1a
```

b) Ajusta un modelo lineal para personas menores de 18 años de edad utilizando
como predictores la `edad` y el `peso`. Interpreta los coeficientes que resultan
del modelo. Si consideras necesario centra los valores de las variables
predictoras.

Primero filtramos la muestra con las personas menores a 18 años

```{r}
menores_edad<-datos1 %>% filter(edad < 18)
menores_edad$genero<-factor(menores_edad$genero) #Convertimos la variable a factor
summary(menores_edad)
```

Calculamos un resumen con estadísticas de dispersión, en este caso la mediana de la edad es de sólo 7 años y la muestra se reduce a 192 observaciones: 92 varones y 100 mujeres. La altura promedio de los datos ahora es de sólo 108 centímetros o 1.08 metros.

Posteriormente, centramos las variables alrededor de su media para poder dar una interpretación más sencilla al modelo lineal para predecir la altura:

```{r, eval = FALSE}
menores_edad<-menores_edad %>% 
  mutate(peso.centrado = peso-mean(peso),
         edad.centrado = edad-mean(edad))
head(menores_edad)
```
Y generamos el modelo con ambos predictores centrados:

```{r}
fit_1b <- stan_glm(altura ~ peso.centrado + edad.centrado, data = menores_edad, seed=SEED, refresh = 0)
print(fit_1b)
```

Obtenemos un resumen del modelo:

```{r}
summary(fit_1b)
```

De los resultados anteriores, vemos que el intercepto representa la altura promedio de los menores de 18 años para una persona con un peso y edad alrededor del promedio la cual corresponde a 108 cm o 1.08 metros como vimos al inicio. Por otro lado, el peso y edad centrada tienen un coeficiente positivo en el modelo, lo cual indica para ambos predictores un incremento sobre el valor promedio centrado del peso y la edad contribuyen a un aumento sobre la predicción de la altura. En el caso del peso.centrado, por cada incremento de una unidad, predicción de la altura aumenta 1.4 cm la altura mientras que en la edad centrada por cada incremento de una unidad, la predicción de altura sube 2.3cm adicionales.

c) Para el modelo resultante, haz gráficos que muestren la relación de la
variable objetivo con los predictores. De igual forma, incorpora en la
visualización la respuesta del modelo lineal junto con intervalos de predicción
al 89\% y 97\%, de tal forma que incorpores la incertidumbre que se ha
cuantificado en tu gráfico.

```{r}
g_1c_x1y<-menores_edad %>%
  ggplot(aes(x=peso.centrado,y=altura)) +
  geom_point()+
  geom_smooth(method = "lm")

g_1c_x2y<-menores_edad %>%
  ggplot(aes(x=edad.centrado,y=altura)) +
  geom_point()+
  geom_smooth(method = "lm")

g_1c_x1y+g_1c_x2y
```
Se aprecia una relación cercana a la lineal con ambos predictores.

d) Supongamos que tenemos una amiga que es experta en
[alometría](https://es.wikipedia.org/wiki/Alometr%C3%ADa) y les menciona que el
peso es suficiente, pero que se debería de incorporar en términos de una escala
logarítmica. Ajusta el modelo con todos las observaciones y compara con el
modelo del inciso a) y un modelo adicional que sólo incorpora el `peso`. ¿Cuál
parece tener mejor capacidad predictiva?

```{r}
howell<-howell %>%
  mutate(log.peso = log(peso))
head(howell)
```
Primero creamos la variable log.peso donde calculamos el logaritmo natural aplicado al peso sobre todas las observaciones de nuestra muestra.

```{r}
fit_1d_v1 <- stan_glm(altura ~ log.peso, data = howell, seed=SEED, refresh = 0)
summary(fit_1d_v1)
```

Después de calcular este primer modelo, observamos que el coeficiente del intercepto es negativo. Por ello, se decidió centrar la variable de log.peso alrededor de la media de log.peso para generar una interpretación del modelo.

```{r}
howell<-howell %>%
  mutate(log.peso.centrado = log.peso-mean(log.peso))
head(howell)
```

```{r}
fit_1d <- stan_glm(altura ~ log.peso.centrado, data = howell, seed=SEED, refresh = 0)
summary(fit_1d)
```

Ya que el signo del coeficiente es positivo nos quedaremos con esta versión para compararla con el del inciso a. Es decir, utilizamos los criterios de información de los modelos para medir la capacidad predictiva del modelo del inciso a) y d) medimos qué tan bien predice cada modelo en datos que no se han observado por medio de la devianza y haciendo uso de validación cruzada con los métodos de waic y loo.

Primero calculamos la devianza de ambos modelos con waic:

```{r}
waic_1a<-waic(fit_1a) #calcula: elpd_waic que corresponde a la log-densidad; p_waic: el número efectivo de parámetros; waic: la devianza del modelo así como suss errores estándar variando sobre todas las observaciones
waic_1d<-waic(fit_1d)

comparativo_waic_1d<-cbind(waic_1a,waic_1d)
comparativo_waic_1d
```

Y los resultados arrojan que el modelo es el d) que incorpora el peso en escala logarítmica como predictor tiene un mejor desempeño ya que es el de menor devianza 3,330 en contraste con el del inciso a) 3,982.

Luego generamos un comparativo en términos de la log-densidad predictiva con el método loo_compare.

```{r}
comparativo_diff_waic_1d<-loo_compare(waic_1a,waic_1d) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_waic_1d
```

Estos resultados también identifican al modelo del inciso d como el mejor pues tiene una mayor log-densidad predictiva. Además se aprecia una diferencia relativamente grande en la log-densidad predictiva y el error estándar del modelo d con respecto al del inciso a.

Por último comparamos los modelos con validación cruzada:

```{r}
loo_1a<-loo(fit_1a) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1a
```

```{r}
loo_1d<-loo(fit_1d)
loo_1d
```
En ambos casos, el diagnóstico que loo arroja es que podemos usar dicho criterio y además las estadísticas coinciden con las obtenidas con el método waic. Por lo que la conclusión no cambia, el mejor modelo también resulta ser el del inciso d bajo esta comparación.

```{r}
comparativo_diff_loo_1d<-loo_compare(loo_1a,loo_1d) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_loo_1d
```

e) ¿Cómo interpretas los coeficientes del mejor modelo del inciso `d`?

Como ya mencionamos, el mejor modelo para la predicción de la variable altura fue el d: altura ~ log.peso.centrado, donde utilizamos la variable log(peso) fue centrada alrededor de su media. Primero mostramos los coeficientes de este modelo:

```{r}
print(fit_1d)
```

De lo anterior se interpreta al intercepto de 138.3 como la estimación para la altura promedio en centímetros de un individuo promedio con un log.peso promedio.centrado (log-kg). El valor del coeficiente $\beta_0$ para la log.peso.centrado de 47.1 significa que un incremento de una unidad en la variable log.peso.centrado aumenta 47.1 cm la predicción sobre la altura del individuo.

f) Ahora estudiaremos el efecto de la distribución previa. Para esto
consideraremos. La variable de `edad` centrada y probaremos distintos polinomios
como predictores. Consideraremos potencias desde 0 hasta términos de grado 6.
Ajusta esta colección de posibles modelos. 

```{r}
howell.centrado<-datos1 %>% 
  mutate(edad.centrada = edad-mean(edad))
howell.centrado$genero<-factor(howell$genero) #Convertimos la variable a factor
head(howell.centrado)
```

```{r}
fit_1f_g1 <- stan_glm(altura ~ edad.centrada, data = howell.centrado, seed=SEED, refresh = 0)
summary(fit_1f_g1)
```

```{r}
fit_1f_g2 <- stan_glm(altura ~ poly(edad.centrada,2,raw=TRUE), data = howell.centrado, seed=SEED, refresh = 0)
summary(fit_1f_g2)
```


g) Para cada modelo en el inciso de arriba, genera gráficos que muestren las
predicciones junto con las bandas de predicción. 

```{r}

```


h) Realiza una evaluación de los modelos resultantes con el criterio de
información que consideres más apropiado.


```{r}

```

i) Ahora ajustaremos un polinomio de grado 6 pero incorporaremos distribuciones
previas mas restrictivas. Es decir, considera que $\beta_k \sim \mathsf{N}(0,
\sqrt{5})$ para toda $k.$ Nota que la desviación estandar es $\sqrt{5}.$ Evalúa
el criterio de información que utilizaste en el inciso anterior, y compara la
estimación de número efectivo de parámetros. ¿Por qué crees que sucede esto?

compara la estimación de número efectivo de parámetros (cómo cambia)

```{r}

```



## Datos: Vinos.

Consideremos el conjunto de datos en `vinos.txt`. Estos datos son evaluaciones
de 20 vinos diferentes, tanto franceses y estadounidenses, realizadas por 9
jueces (también, franceses y estadounidenses) diferentes. El objetivo de este
ejercicio es modelar el `score`, la calificación subjetiva que cada juez asigna
a cada vino. Recomiendo centrarlo para el ajuste de los modelos.

```{r}
datos2<-read_delim("vinos.txt", delim = ";" ) #Cargamos los datos
```

```{r}
vinos<-datos2
vinos$wine.amer<-factor(vinos$wine.amer)
vinos$judge.amer<-factor(vinos$judge.amer)
glimpse(vinos)
```



```{r}
summary(vinos)
```


a) En este inciso, sólo considera la variación entre jueces y
vinos. Ajusta un modelo de regresión lineal utilizando estos predictores.
Justifica tu distribución _a priori_. ¿Cómo interpretas la variación entre
jueces individuales y vinos individuales? ¿Notas algún patrón (puedes utilizar
`mcmc_areas`)? ¿Qué jueces dieron las calificaciones más altas / más bajas? ¿Qué
vinos fueron calificados como peores / mejores en promedio?


b) Ajusta con la previa _default_ en `stan_glm`. Después, ajusta de nuevo el
modelo con una distribución a priori regularizada (incorpora `prior = hs()` en
las opciones). ¿Que observas al comparar la $R^2$-Bayesiana de ambos modelos?
¿Cómo explicas éste comportamiento? Por otro lado, calcula la capacidad
predictiva por medio de `loo` o `waic` (el que tu elijas) en ambos y describe lo
que observas en el estadistico que describe el número efectivo de parámetros.
¿Cómo justificas este comportamiento? ¿Cómo concilias lo observado en la $R^2_B$
y la comparación de devianza entre ambas posibilidades?


c) Ahora considera como predictores `flight`(el tipo de vino), `wine.amer` (de
dónde proviene), y `judge.amer` (indicador si el juez es americano). Para este
inciso no incluyas las variables de los casos anteriores. De igual manera,
justifica la selección de distribución previa que utilizas. ¿Cómo se relacionan
estas estimaciones con lo que observaste en el inciso `a`?

d) Ahora considera todas las posibles interacciones de dos términos con las tres
variables de arriba. Explica lo que significa cada término e interpreta los
coeficientes. ¿Cómo se relacionan estos resultados con los del inciso `a` de
esta sección?


### Datos: 

Utiliza los datos en `nettle.txt` para evaluar la hipótesis de que la diversidad
lingüística es producto de la seguridad alimentaria. Los datos contienen mediciones para: 

1) `country`: Nombre del país.
2) `num.leng`: Número de lenguajes identificados en dicho país.
3) `area`: Area medida en kilómetros cuadrados.
4) `k.pop`: Población en miles. 
5) `num.stations`: Número de estaciones que proveen las siguientes. 
6) `mean.growing.season`: Duración promedio de la temporada de cosecha, medida
en meses. 
7) `sd.growing.season`: Desviación estándar de la duración de la
temporada de cosecha, medidad en meses.

La idea es que, en las ecologías productivas, las personas no necesitan grandes
redes sociales para protegerse contra el riesgo de escasez de alimentos. Esto
significa que los grupos culturales pueden ser más pequeños y más
autosuficientes, lo que lleva a más idiomas per cápita. Utiliza el número de
idiomas per cápita como resultado:

```{r}
datos3<-read_delim("nettle.txt", delim = ";" ) #Cargamos los datos
```

```{r}
nettle<-datos3
glimpse(nettle)
```


```{r, eval = FALSE}
nettle %>% 
    mutate(leng.per.cap = num.leng/k.pob)
```

Utilice el logaritmo de esta nueva variable como el objetivo de un modelo de
regresión. Este problema tiene un final abierto, lo que les permite decidir cómo
abordar las hipótesis y las predicciones inciertas que proporciona el modelo. Si
creen que necesita usar WAIC/LOO en cualquier momento, háganlo. Si creen que necesitan
cierta distribución previa, argumenten por ella. Si creen que necesitan mostrar
las predicciones de cierta manera, háganlo. Traten de evaluar honestamente
los efectos principales de la temporada media de crecimiento
(`mean.growing.season`) y la desviación de la temporada de crecimiento
(`sd.growing.season`), así como su interacción.

a) Evalúe la hipótesis de que la diversidad lingüística, medida por
`log(lang.per.cap)`, está asociada positivamente con la duración promedio de la
temporada de crecimiento, `mean.growing.season`. Considera tambíen  `log(area)`
en tu modelo (no como una interacción). Interpreten sus resultados.

b) Ahora evalúen la hipótesis de que la diversidad lingüística está asociada
negativamente con la desviación estándar de la duración de la temporada de
crecimiento. Esta hipótesis se deriva de la incertidumbre en la cosecha que
favorece la seguridad social a través de redes sociales más amplias y, por lo
tanto, menos idiomas. Nuevamente, considere `log(area)` como una covariable (no
una interacción). Interpreten sus resultados.

c) Finalmente, evalúen la hipótesis de que `mean.growing.season` y
`sd.growing.season` interactúan para reducir sinérgicamente la diversidad del
lenguaje. La idea es que, en naciones con temporadas de cultivo en promedio más
largas, la alta variación hace que el almacenamiento y la redistribución sean
aún más importantes de lo que serían de otra manera. De esa manera, las personas
pueden cooperar para preservar y proteger las ganancias inesperadas que se
utilizarán durante las sequías.
